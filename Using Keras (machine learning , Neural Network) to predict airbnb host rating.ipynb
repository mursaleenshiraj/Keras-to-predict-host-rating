{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras (machine learning/Neural Network) to predict the host rating in airbnb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I demonstarte a simple example of how we can use kears to buuild a model very easily. I show an application in forecasting review score of airbnb hosts based on only a few features. I use a small data from inside airbnb.\n",
    "\n",
    "In an attempt to keep the notebook short, I have not shown the data collection and preparation work that were put into this. I still am keeping s small part of variable creation and cleaning in this notebook just to remind how important that part is in any data project. Data cleaning and visualization is a very important part of any data project. I am going to put some demonstration on EDA later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"E:\\JY\\Boston\\bostondetailedlistingsdf20200803.csv\", low_memory=False)\n",
    "# there are some text data in the file, so use low_memory=false option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going to work with a smaller number of features in this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\"host_since\", \"host_response_time\", \"host_response_rate\", \"host_acceptance_rate\", \"host_is_superhost\",\n",
    "   \"host_total_listings_count\", \"host_has_profile_pic\", \"host_identity_verified\", \"room_type\",\n",
    "   \"bathrooms\", \"bedrooms\", \"beds\"]\n",
    "\n",
    "target=\"review_scores_rating\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([df[features], df[target]], axis=1) #create a smaller df, as I know I am only using this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick inspection of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_since</th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>room_type</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>review_scores_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-09-14</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>100%</td>\n",
       "      <td>100%</td>\n",
       "      <td>t</td>\n",
       "      <td>2.0</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-05-11</td>\n",
       "      <td>within an hour</td>\n",
       "      <td>100%</td>\n",
       "      <td>50%</td>\n",
       "      <td>t</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-06-07</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>100%</td>\n",
       "      <td>100%</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>94%</td>\n",
       "      <td>96%</td>\n",
       "      <td>f</td>\n",
       "      <td>1.0</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-08-05</td>\n",
       "      <td>within a few hours</td>\n",
       "      <td>100%</td>\n",
       "      <td>87%</td>\n",
       "      <td>f</td>\n",
       "      <td>2.0</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_since  host_response_time host_response_rate host_acceptance_rate  \\\n",
       "0  2013-09-14      within an hour               100%                 100%   \n",
       "1  2009-05-11      within an hour               100%                  50%   \n",
       "2  2012-06-07  within a few hours               100%                 100%   \n",
       "3  2011-01-02  within a few hours                94%                  96%   \n",
       "4  2012-08-05  within a few hours               100%                  87%   \n",
       "\n",
       "  host_is_superhost  host_total_listings_count host_has_profile_pic  \\\n",
       "0                 t                        2.0                    t   \n",
       "1                 t                        1.0                    t   \n",
       "2                 f                        1.0                    t   \n",
       "3                 f                        1.0                    t   \n",
       "4                 f                        2.0                    t   \n",
       "\n",
       "  host_identity_verified        room_type  bathrooms  bedrooms  beds  \\\n",
       "0                      t     Private room        1.0       1.0   1.0   \n",
       "1                      t     Private room        1.0       1.0   1.0   \n",
       "2                      t     Private room        1.0       1.0   1.0   \n",
       "3                      t  Entire home/apt        1.0       1.0   2.0   \n",
       "4                      t     Private room        2.0       1.0   1.0   \n",
       "\n",
       "   review_scores_rating  \n",
       "0                  96.0  \n",
       "1                  98.0  \n",
       "2                  95.0  \n",
       "3                  86.0  \n",
       "4                  97.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() # take a quick look at the data. notice the % sign in some variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new variables. I am interested in the hosting experience, creating some intermediate variables so the work is easier to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"host_since\"]=pd.to_datetime(df[\"host_since\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"beg_month\"]=df[\"host_since\"].dt.month\n",
    "df[\"beg_year\"]=df[\"host_since\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"curr_year\"]=2015\n",
    "df[\"curr_month\"]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"exper\"]=(df[\"curr_year\"]-df[\"beg_year\"])*12+df[\"curr_month\"]-df[\"beg_month\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the variable types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_since                   datetime64[ns]\n",
       "host_response_time                   object\n",
       "host_response_rate                   object\n",
       "host_acceptance_rate                 object\n",
       "host_is_superhost                    object\n",
       "host_total_listings_count           float64\n",
       "host_has_profile_pic                 object\n",
       "host_identity_verified               object\n",
       "room_type                            object\n",
       "bathrooms                           float64\n",
       "bedrooms                            float64\n",
       "beds                                float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features].dtypes # check the data types of these variables. Notice the % signs made the numeric values to be a string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"host_response_rate\"]=df[\"host_response_rate\"].str.replace(\"%\", \"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"host_acceptance_rate\"]=df[\"host_acceptance_rate\"].str.replace(\"%\", \"\").astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another df with the dummy variables. I prefer creating new DF instead of using the original df with the same name. I think this helps when something goes wrong. But not super important, this is more of a preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.get_dummies(df, columns=[\"host_is_superhost\", \"host_has_profile_pic\", \"host_identity_verified\",\n",
    "                                \"room_type\", \"host_response_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152354, 27)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape\n",
    "# compare the shape of this df with the shape we earlier saw. lose much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entire home/apt    96295\n",
       "Private room       53895\n",
       "Shared room         1817\n",
       "Hotel room           347\n",
       "Name: room_type, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"room_type\"].value_counts() \n",
    "# this helps to see what room types are more common and if the data is really sparse in some dimension.\n",
    "# I have checked other categorical variables as well. Not showing all of them to keep the notebook shorter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['host_since', 'host_response_rate', 'host_acceptance_rate',\n",
       "       'host_total_listings_count', 'bathrooms', 'bedrooms', 'beds',\n",
       "       'review_scores_rating', 'beg_month', 'beg_year', 'curr_year',\n",
       "       'curr_month', 'exper', 'host_is_superhost_f', 'host_is_superhost_t',\n",
       "       'host_has_profile_pic_f', 'host_has_profile_pic_t',\n",
       "       'host_identity_verified_f', 'host_identity_verified_t',\n",
       "       'room_type_Entire home/apt', 'room_type_Hotel room',\n",
       "       'room_type_Private room', 'room_type_Shared room',\n",
       "       'host_response_time_a few days or more',\n",
       "       'host_response_time_within a day',\n",
       "       'host_response_time_within a few hours',\n",
       "       'host_response_time_within an hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.keys() # column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "varlist=[\"host_total_listings_count\", \"bathrooms\", \"bedrooms\", \"beds\",\n",
    "          \"exper\", 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "         'host_identity_verified_t', 'room_type_Entire home/apt', 'room_type_Private room', \n",
    "          'host_response_time_within an hour',\n",
    "         'host_response_time_within a few hours', 'review_scores_rating'] \n",
    "# all the variables I am considering for the model.\n",
    "# see how this is differnet from the original list of features we started with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "host_total_listings_count                 True\n",
       "bathrooms                                 True\n",
       "bedrooms                                  True\n",
       "beds                                      True\n",
       "exper                                     True\n",
       "host_is_superhost_t                      False\n",
       "host_has_profile_pic_t                   False\n",
       "host_identity_verified_t                 False\n",
       "room_type_Entire home/apt                False\n",
       "room_type_Private room                   False\n",
       "host_response_time_within an hour        False\n",
       "host_response_time_within a few hours    False\n",
       "review_scores_rating                      True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[varlist].isnull().any() # check which variables have missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this example I am going to drop the variables with missing values,\n",
    "# but there are better ways to deal with missing values like imputing with some function of the observed values.\n",
    "# I don't recommend dropping variables because of missing values.\n",
    "\n",
    "df3=df2[varlist].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120749, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.shape # see how much information we missed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar=StandardScaler() \n",
    "# I recommend scaling the data before using in Keras models.\n",
    "# cerate the standard scaler from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans=scalar.fit(df3[varlist]) # fit the standard scaler on the data. \n",
    "# I have scaled the target variable as well. Not recommend for categorical target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ft=[\"host_total_listings_count\", \"bathrooms\", \"bedrooms\", \"beds\",\n",
    "          \"exper\", 'host_is_superhost_t', 'host_has_profile_pic_t',\n",
    "         'host_identity_verified_t', 'room_type_Entire home/apt', 'room_type_Private room', \n",
    "          'host_response_time_within an hour',\n",
    "         'host_response_time_within a few hours'] # these are the clean feature variables I am using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.DataFrame(trans.transform(df3[varlist]), columns=varlist) # creating another df for the transformed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df4[\"review_scores_rating\"] # target variable in the model\n",
    "\n",
    "l=len(clean_ft) # used to set the input shape in the network\n",
    "X=df4[clean_ft] # features data used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the sample data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size = 0.1,\n",
    "                                                    random_state = 1) \n",
    "# split the sample for checking overfitting later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use keras to build a neural net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:68: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model=Sequential() # start keras model. There are ways to suppress the warnings, I prefer keeping them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:507: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3878: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:126: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3138: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# add layers to the model. I have kept the dimension small. But you can play aorund and try a much complex structure.\n",
    "\n",
    "model.add(Dense(8, kernel_initializer='he_normal', input_shape=(l, ), activation='relu'))\n",
    "model.add(Dropout(0.5)) \n",
    "# randmoly dropping some nods/weights in the network. dropping 50%. essentially setting weight to zero.\n",
    "model.add(Dense(4, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:757: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mse') # compile the model.\n",
    "# for continuous target variable, it is common to use loss function of mse.\n",
    "# in case of binary target, can use cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:976: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:963: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2499: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:167: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:183: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:192: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "108674/108674 [==============================] - 7s 60us/step - loss: 2.7192\n",
      "Epoch 2/20\n",
      "108674/108674 [==============================] - 4s 33us/step - loss: 1.0922\n",
      "Epoch 3/20\n",
      "108674/108674 [==============================] - 3s 30us/step - loss: 1.0163: 1s - loss: 1.02 - ETA: 1\n",
      "Epoch 4/20\n",
      "108674/108674 [==============================] - 3s 32us/step - loss: 1.0160\n",
      "Epoch 5/20\n",
      "108674/108674 [==============================] - 5s 48us/step - loss: 1.0077: 0s - loss: 1.00\n",
      "Epoch 6/20\n",
      "108674/108674 [==============================] - 3s 25us/step - loss: 1.0055: 1s - - ETA\n",
      "Epoch 7/20\n",
      "108674/108674 [==============================] - 3s 25us/step - loss: 1.0048\n",
      "Epoch 8/20\n",
      "108674/108674 [==============================] - 3s 26us/step - loss: 1.0045: 0s -\n",
      "Epoch 9/20\n",
      "108674/108674 [==============================] - 3s 23us/step - loss: 1.0031\n",
      "Epoch 10/20\n",
      "108674/108674 [==============================] - 2s 22us/step - loss: 1.0026\n",
      "Epoch 11/20\n",
      "108674/108674 [==============================] - 2s 22us/step - loss: 1.0021\n",
      "Epoch 12/20\n",
      "108674/108674 [==============================] - 2s 23us/step - loss: 1.0016\n",
      "Epoch 13/20\n",
      "108674/108674 [==============================] - 2s 22us/step - loss: 1.0014\n",
      "Epoch 14/20\n",
      "108674/108674 [==============================] - 2s 23us/step - loss: 1.0002\n",
      "Epoch 15/20\n",
      "108674/108674 [==============================] - 2s 22us/step - loss: 0.9991\n",
      "Epoch 16/20\n",
      "108674/108674 [==============================] - 2s 23us/step - loss: 0.9980\n",
      "Epoch 17/20\n",
      "108674/108674 [==============================] - 2s 20us/step - loss: 0.9961\n",
      "Epoch 18/20\n",
      "108674/108674 [==============================] - 2s 20us/step - loss: 0.9946\n",
      "Epoch 19/20\n",
      "108674/108674 [==============================] - 2s 20us/step - loss: 0.9922\n",
      "Epoch 20/20\n",
      "108674/108674 [==============================] - 2s 20us/step - loss: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2611b837278>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, batch_size=128) # fit the model with the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9319346206578162"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=0) \n",
    "# test performance on test data. This is pretty good based on how simple a network we used and the size of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
